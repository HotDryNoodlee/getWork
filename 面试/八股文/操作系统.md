





## 进程和线程之间有什么区别

进程和线程是操作系统中的两个基本概念，它们在程序执行中扮演着不同的角色。以下是它们之间的主要区别：

1. 定义
    * 进程（Process）：是操作系统分配资源的基本单位。每个进程都有自己独立的内存空间、文件句柄和其他资源。进程是一个正在执行的程序的实例。
    * 线程（Thread）：是进程中的一个执行路径。一个进程可以包含多个线程，这些线程共享进程的内存空间和资源，但各自有独立的执行路径和栈。
2. 资源分配
    * 进程：每个进程有独立的内存空间（包括代码段、数据段、堆和栈），并且拥有自己的资源（如文件句柄、信号处理等）。进程之间是相互隔离的，无法直接访问彼此的内存。
    * 线程：线程共享进程的内存空间和资源，但拥有自己独立的栈和寄存器。因为线程共享进程资源，所以线程之间的通信比进程间的通信更高效，但也更容易出现同步问题。
3. 执行开销
    * 进程：由于进程之间相互隔离，进程切换（上下文切换）的开销较大，因为操作系统需要切换内存空间和更新许多管理信息。
    * 线程：线程切换的开销较小，因为线程之间共享进程的资源，不需要切换内存空间，只需要保存和恢复少量的上下文信息。
4. 通信方式
    * 进程：进程间通信（IPC）通常依赖于操作系统提供的机制，如管道、消息队列、共享内存、信号等，这些方式相对复杂且效率较低。
    * 线程：线程之间可以直接共享进程的全局变量或堆内存，通信相对简单且高效，但需要使用同步机制（如锁、信号量）来避免竞态条件。
5. 容错性
    * 进程：由于进程之间是隔离的，一个进程的崩溃通常不会影响到其他进程。
    * 线程：线程共享进程资源，如果一个线程崩溃，可能导致整个进程的崩溃，因为它可能破坏共享的内存或资源。
6. 创建开销
    * 进程：创建一个新进程的开销较大，需要为其分配独立的资源和内存空间。
    * 线程：创建一个新线程的开销较小，因为它与现有线程共享大部分资源。

## 解释一下用户态和核心态，什么场景下，会发生内核态和用户态的切换？

用户态和核心态是操作系统中用于保护系统稳定性和安全性的两种不同的执行模式。
**用户态**（User Mode）：
在用户态下，运行的程序不能直接访问硬件资源或者执行特权指令。如果一个程序在用户态下执行了这些操作，操作系统会将其视为非法操作，并产生一个中断来阻止它。用户态程序通常受限于它们自己的地址空间，无法访问其他进程的地址空间，这样可以防止错误或恶意程序破坏系统稳定性。
**核心态**（Kernel Mode）：
核心态也称为系统态或特权模式，是操作系统内核执行代码时的状态。在核心态下，执行的代码具有最高的权限，可以直接访问所有的内存和硬件资源，执行任何CPU指令集，包括特权指令。这意味着核心态的程序可以完成用户态程序无法完成的任务，如管理进程、内存、设备驱动程序和系统资源等。

**内核态和用户态的切换场景**：
1. **系统调用**（System Call）：
   当用户程序需要执行一些只有操作系统才能执行的操作时（如文件读写、网络通信等），它会通过系统调用请求操作系统提供服务。这时，处理器从用户态切换到核心态，以便内核执行相应的操作。
2. **硬件中断**（Hardware Interrupt）：
   当硬件设备（如磁盘、网络适配器、键盘等）需要操作系统处理某个事件时，它会发送一个中断信号给CPU。CPU接收到中断后，会暂停当前的用户态程序，切换到核心态，执行中断处理程序。
3. **异常**（Exception）：
   当正在执行的程序发生错误（如页面错误、非法操作码、除以零等）时，CPU会从用户态切换到核心态，以便内核处理这些异常情况。
4. **软件中断**（Software Interrupt）：
   程序可以通过软件中断指令（如Linux的int 0x80或sysenter指令）显式地请求切换到核心态。
操作系统通过这些机制来保证系统的稳定性和安全性，同时也为应用程序提供了执行其任务所需的服务。内核态和用户态的切换是现代操作系统管理资源和保护系统免受不稳定或恶意程序影响的关键机制。

## 进程调度算法你了解多少

进程调度算法是操作系统中的一个关键部分，它负责决定哪个进程将获得CPU时间以及它们将获得多长时间。以下是一些常见的进程调度算法：
1. **先来先服务（FCFS, First-Come, First-Served）**：
   这是最简单的调度算法。进程按照它们到达就绪队列的顺序被调度。FCFS可能会导致“饥饿”现象，特别是对于长作业，因为它不考虑作业的长度。
2. **短作业优先（SJF, Shortest Job First）**：
   这个算法选择预计运行时间最短的作业来执行。它可以是非抢占式的，也可以是抢占式的（称为最短剩余时间优先，SRTF）。SJF算法可能导致长作业饥饿。
3. **优先级调度**：
   每个进程被赋予一个优先级，调度器根据优先级来选择下一个要执行的进程。更高优先级的进程会先于低优先级的进程执行。这可以是抢占式的，也可以是非抢占式的。
4. **轮转调度（Round Robin, RR）**：
   这是抢占式调度算法，每个进程被分配一个固定的时间片（quantum）。进程轮流使用CPU，如果一个进程在其时间片结束时还没有完成，它将被放回就绪队列的末尾。
5. **多级反馈队列（Multilevel Feedback Queue, MFQ）**：
   这个算法将就绪队列分成多个级别，每个级别有不同的优先级。进程可以在队列之间移动，这取决于它们的行为和需求。这个算法试图结合SJF和RR的优点。
6. **最高响应比优先（HRRN, Highest Response Ratio Next）**：
   响应比是等待时间加上估计运行时间的函数。这个算法选择具有最高响应比的进程来执行。
这些算法各有优缺点，它们的选择取决于特定的应用场景和系统需求。例如，实时系统可能需要使用特定的实时调度算法来保证任务的截止时间。


## 进程间有哪些通信方式
进程间的通信方式主要包括以下几种：
1. **管道（Pipes）**：管道是一种半双工的通信方式，只能在具有亲缘关系的进程间使用，例如父子进程。
2. **命名管道（FIFOs）**：命名管道是一种特殊的文件，可以在无关进程之间进行通信。
3. **消息队列（Message Queues）**：消息队列允许一个或多个进程向队列中写入或读取消息，它独立于发送和接收进程的存在。
4. **信号量（Semaphores）**：信号量通常用于进程间的同步操作，而不是用于传递大量数据。
5. **共享内存（Shared Memory）**：共享内存允许多个进程访问同一块内存空间，是最快的IPC方式，但需要同步机制来避免竞态条件。
6. **套接字（Sockets）**：套接字是一种可以在不同主机上的进程间进行通信的机制，支持网络通信。
7. **信号（Signals）**：信号是一种较为简单的通信方式，用于通知接收进程某个事件已经发生。
每种通信方式都有其适用的场景和优缺点，开发者可以根据实际需求选择最合适的通信机制。

## 解释一下进程同步和互斥，以及如何实现进程同步和互斥
进程同步和互斥是操作系统中处理多进程协作时的重要概念。
**进程同步**是指多个进程按照一定的顺序和时序关系协调它们的工作，以共同完成一个任务。在同步过程中，各个进程可能需要交换信息或等待其他进程达到某个状态，以确保数据的一致性和执行的正确性。
**进程互斥**是指当多个进程访问共享资源时，任意时刻只允许一个进程访问该资源，防止多个进程同时操作同一资源而引发数据不一致或错误。
以下是实现进程同步和互斥的常见方法：
**实现进程同步的方法：**
1. **信号量（Semaphores）**：
   - **二进制信号量**可以用来实现互斥，其值只能是0或1。
   - **计数信号量**可以用来实现同步，其值可以是任何非负整数，用于表示资源的可用数量。
2. **条件变量（Condition Variables）**：
   - 条件变量通常与互斥锁一起使用，允许进程在某些条件下挂起或被唤醒。
**实现进程互斥的方法：**
1. **互斥锁（Mutex Locks）**：
   - 互斥锁是一种保证共享资源在同一时间只能被一个进程访问的机制。
2. **临界区（Critical Sections）**：
   - 临界区是指访问共享资源的代码段，进程在进入临界区之前必须先获取锁。
3. ** Peterson算法**：
   - 对于两个进程的情况，Peterson算法是一个不需要硬件支持的软件解决方案，它使用两个标志和一个turn变量来确保互斥。
以下是具体的实现步骤：
**进程同步的实现步骤：**
1. 定义信号量，初始化其值。
2. 在每个进程的代码中，按照需要执行`P操作`（减操作）来请求资源，如果资源不可用则阻塞。
3. 在进程完成对共享资源的操作后，执行`V操作`（加操作）来释放资源，并唤醒等待的进程。
**进程互斥的实现步骤：**
1. 在访问共享资源之前，进程尝试获取互斥锁。
2. 如果互斥锁已被其他进程持有，则当前进程阻塞，直到互斥锁被释放。
3. 当进程完成对共享资源的访问后，释放互斥锁，以便其他进程可以访问。
通过这些机制，可以有效地控制进程的执行顺序，确保数据的一致性和系统的稳定性。

## 什么是死锁，如何避免死锁？
死锁是指两个或多个进程在执行过程中，因争夺资源而造成的一种互相等待的现象，如果没有外力干预，这些进程都将无法向前推进。
**死锁的四个必要条件：**
1. **互斥条件**：资源不能被多个进程同时使用，只能由一个进程独占。
2. **持有和等待条件**：进程至少持有一个资源，并且正在等待获取其他进程持有的资源。
3. **非抢占条件**：已经分配给进程的资源在该进程完成任务前不能被抢占。
4. **循环等待条件**：存在一种进程资源的循环等待链，每个进程至少持有一个资源，并等待获取下一个进程所持有的资源。
**避免死锁的方法：**
1. **破坏互斥条件**：
   - 可以通过假脱机技术，允许共享资源在一段时间内可以被多个进程访问。
2. **破坏持有和等待条件**：
   - 进程在开始执行前必须一次性请求所有需要的资源。
   - 如果无法一次性分配所有资源，进程可以在持有部分资源的情况下释放已持有的资源，然后重新尝试获取所有资源。
3. **破坏非抢占条件**：
   - 允许资源被抢占，即当一个进程请求资源时，可以从占有资源的进程中抢占所需资源。
4. **破坏循环等待条件**：
   - 对所有资源类型进行完全排序，并要求每个进程按顺序请求资源，从而避免循环等待。
除此之外，以下是一些避免死锁的策略：
- **资源分配策略**：
  - **银行家算法**：在分配资源之前，系统会检查分配是否可能导致系统进入不安全状态，只有确认安全才进行分配。
  - **避免策略**：在进程请求资源时，系统会判断分配资源后是否可能导致死锁，只有在不会导致死锁的情况下才分配资源。
- **进程挂起策略**：
  - 当一个进程请求的资源被另一个进程持有，并且后者正在等待其他资源时，可以挂起持有资源的进程，从而打破循环等待。
- **资源分配图**：
  - 通过资源分配图来检测系统是否处于安全状态，从而避免死锁的发生。
通过上述方法，可以在设计系统时避免死锁的发生，或者在死锁发生前采取措施预防。需要注意的是，并非所有系统都能完全避免死锁，因此在设计系统时还需要考虑死锁的检测和恢复策略。

## 介绍一下几种典型的锁
1. 互斥锁：互斥锁是一种最常见的锁类型，用于实现互斥访问共享资源。在任何时刻，只有一个线程可以持有互斥锁，其他线程必须等待直到锁被释放。这确保了同一时间只有一个线程能够访问被保护的资源。
2. 自旋锁：自旋锁是一种基于忙等待的锁，即线程在尝试获取锁时会不断轮询，直到锁被释放。

其他的锁都是基于这两个锁的

* 读写锁：允许多个线程同时读共享资源，只允许一个线程进行写操作。分为读（共享）和写（排他）两种状态。
* 悲观锁：认为多线程同时修改共享资源的概率比较高，所以访问共享资源时候要上锁
* 乐观锁：先不管，修改了共享资源再说，如果出现同时修改的情况，再放弃本次操作。

## 讲一讲你理解的虚拟内存
虚拟内存是现代操作系统中的一个重要功能，它对计算机系统的性能和稳定性有着显著的影响。以下是虚拟内存的主要作用：
1. **扩展物理内存**：
   虚拟内存允许系统使用硬盘空间作为临时的内存使用，这样即使物理内存（RAM）不足，系统也能处理更大的数据集和更多的应用程序。
2. **内存保护**：
   每个进程都有自己的虚拟地址空间，其他进程不能访问这个地址空间。这样可以防止一个进程有意或无意地修改另一个进程的数据，从而提高了系统的稳定性和安全性。
3. **数据持久化**：
   虚拟内存管理系统可以将不常用的内存页交换到硬盘上的交换文件（swap file）或交换分区（swap partition）中，从而为常用的数据腾出物理内存空间。
4. **提高多任务处理能力**：
   通过虚拟内存，操作系统可以为每个运行的应用程序提供看似连续的内存空间，即使物理内存不足，也能让多个应用程序同时运行。
5. **简化编程**：
   虚拟内存为程序员提供了一个连续的、大块的内存地址空间，这简化了内存管理，因为程序员不需要关心物理内存的实际布局。
6. **内存分配灵活性**：
   虚拟内存允许操作系统动态地分配和回收内存，而不需要连续的物理内存空间。这使得内存分配更加灵活和高效。
7. **页面置换策略**：
   虚拟内存系统可以使用不同的页面置换策略（如LRU、FIFO等）来决定哪些内存页应该被交换到硬盘上，从而优化内存使用。
8. **减少外部碎片**：
   由于虚拟内存管理器可以动态地分配和释放内存页，因此可以减少外部碎片的问题，即物理内存中分散的小空闲块。
9. **提高系统吞吐量**：
   虚拟内存使得操作系统可以更有效地使用可用资源，从而提高了整个系统的吞吐量。
总之，虚拟内存是现代计算机系统中不可或缺的组成部分，它通过提供一种抽象的内存模型，使得计算机能够更高效、更安全地运行多个应用程序和进程。

## 有哪些页面置换算法
页面置换算法是在操作系统中管理虚拟内存时使用的一种策略，用于决定当需要新的页面载入内存而内存已满时，哪个页面应该被替换出去。以下是一些常见的页面置换算法：
1. **先进先出（FIFO）算法**：
   - 这是最简单的页面置换算法。在这种算法中，操作系统维护一个队列，最先进入内存的页面在需要置换时最先被替换出去。
2. **最近最少使用（LRU）算法**：
   - LRU算法基于这样一个假设：长期未被使用的页面很可能在未来也不会被使用。因此，当需要置换页面时，会替换最长时间未被使用的页面。
3. **最不经常使用（LFU）算法**：
   - LFU算法根据页面被访问的频率来决定置换哪个页面。最少访问的页面被认为是最不可能会被再次访问的，因此被优先置换。
4. **最优页面置换算法（OPT）**：
   - 这是一种理想化的算法，它假定操作系统可以预知未来的页面请求序列，从而在每次页面置换时替换掉将来最长时间内不会被访问的页面。实际上，这是不可实现的，但它提供了一个性能评估的基准。
5. **时钟（Clock）算法**：
   - 时钟算法是一种简单的近似LRU算法。它使用一个指针在页面集合上循环，类似于时钟的移动，以决定哪个页面被替换。
每种算法都有其优缺点，适用于不同的场景和需求。在实际应用中，操作系统会根据具体的工作负载和性能目标来选择合适的页面置换算法。

## 说一下 select、poll、epoll
`select`、`poll`和`epoll`是Linux操作系统中用于IO多路复用的三种机制。它们允许程序同时监视多个文件描述符，以便它们中的任何一个准备好进行IO操作时能够得到通知。以下是它们之间的主要区别：
### select：
- **能力限制**：`select`能够监视的文件描述符数量有最大限制，通常是1024或2048，取决于系统定义的`FD_SETSIZE`。
- **效率问题**：每次调用`select`都需要重新传递整个文件描述符集合到内核空间，并且需要内核遍历整个集合来确定哪些文件描述符就绪。
- **数据结构**：使用位掩码（bitmask）来表示文件描述符集合，分别用于读、写、异常条件的监视。
- **阻塞/非阻塞**：`select`可以以阻塞或非阻塞方式工作。
- **跨平台兼容性**：`select`在多数Unix-like系统中都得到支持。
### poll：
- **能力限制**：`poll`没有最大文件描述符数量的限制，它只受系统资源的限制。
- **效率问题**：与`select`类似，每次调用`poll`也需要传递整个事件数组到内核，并且由内核遍历。
- **数据结构**：`poll`使用一个数组来传递文件描述符和事件信息，不再使用位掩码。
- **事件类型**：`poll`可以处理更多类型的事件，比`select`更加灵活。
- **跨平台兼容性**：`poll`在一些Unix-like系统中可用，但不如`select`普遍。
### epoll：
- **能力限制**：`epoll`没有文件描述符数量的限制，只受系统资源的限制。
- **效率问题**：`epoll`通过在内核中维护一个事件表来避免每次调用时都传递文件描述符集合。它使用`epoll_ctl`来添加或修改要监视的文件描述符，这使得操作效率更高。
- **数据结构**：`epoll`使用事件表，并且可以返回就绪的文件描述符列表，不需要用户遍历整个集合。
- **事件通知**：`epoll`支持边缘触发（ET）和水平触发（LT）两种模式，ET模式在文件描述符状态变化时只通知一次，而LT模式会一直通知直到条件不再满足。
- **跨平台兼容性**：`epoll`是Linux特有的机制，其他Unix-like系统通常不支持。
总结来说，`epoll`相比`select`和`poll`在处理大量文件描述符时具有更高的效率和更好的性能，特别是在高并发情况下。因此，在需要高性能网络服务器应用时，`epoll`通常是首选的IO多路复用机制。


## 协程是什么，和线程有什么区别 进程、线程、协程是几比几比几的关系
协程（Coroutine）是一种程序组件，它允许多个入口点用于暂停和恢复执行的函数，可以在单个线程内实现多任务的并发执行。协程提供了一种更轻量级的并发编程方法，与线程相比，协程有一些关键的区别：
### 协程与线程的区别：
1. **调度**：
   - **线程**：线程由操作系统的线程调度器进行调度，线程切换涉及用户态与内核态之间的转换，这种转换相对较慢。
   - **协程**：协程通常由用户程序自身进行调度，协程切换通常发生在用户态，不需要操作系统介入，因此切换开销更小。
2. **资源开销**：
   - **线程**：每个线程都有自己的堆栈和寄存器状态，线程创建和销毁的开销相对较大。
   - **协程**：协程共享同一线程的堆栈空间，协程的创建和销毁开销非常小。
3. **并发性**：
   - **线程**：多线程可以实现真正的并行计算，特别是在多核处理器上。
   - **协程**：协程通常在单个线程内实现多任务，它们通过协作来交替执行，而不是并行执行。
4. **上下文切换**：
   - **线程**：线程的上下文切换涉及复杂的操作系统操作。
   - **协程**：协程的上下文切换通常只涉及简单的寄存器操作，速度更快。
### 进程、线程、协程的关系：
进程、线程和协程之间的关系不是简单的数字比例关系，而是层次和包含关系。以下是一个简化的描述：
- **进程**：是操作系统进行资源分配和调度的基本单位，每个进程都有自己的地址空间、堆栈、数据段等。
- **线程**：是进程内的一个执行流，是CPU调度的基本单位。一个进程可以包含多个线程，它们共享进程的资源。
- **协程**：是线程内的一个执行单元，通常由程序控制，用于实现协作式的多任务处理。
因此，进程、线程和协程的关系可以表示为：
- **1个进程**可能包含**多个线程**。
- **1个线程**可能包含**多个协程**。
这种关系可以用以下比例表示：
- 进程 : 线程 : 协程 = 1 : N : M
其中N是进程中的线程数，M是线程中的协程数。实际上，这个比例会根据具体的程序设计和操作系统的情况而变化。协程的数量通常远大于线程的数量，因为协程更加轻量级，可以创建成千上万个而不会对系统造成过大的负担。


## cpu是怎么从内存中读数据的


## 软链接和硬链接

在文件系统中，软链接（Symbolic Link）和硬链接（Hard Link）是两种不同的文件链接方式，它们用于不同的目的，具有不同的特性。

### 1. 硬链接 (Hard Link)
硬链接是指多个文件名（或路径名）指向同一个物理存储块上的数据。简单来说，硬链接和原始文件是平等的，都是对相同数据块的引用。

- **特点**:
  - **相同的 inode**: 硬链接文件和原文件共享相同的 inode，意味着它们指向同一个文件数据块。
  - **不可链接到目录**: 硬链接不能指向目录，主要是为了防止创建循环链接，从而破坏文件系统的结构。
  - **删除无影响**: 如果删除了其中一个硬链接，其他指向相同数据块的链接仍然有效，文件数据不会丢失，直到最后一个链接被删除时，数据才会被释放。
  - **同一文件系统**: 硬链接只能在同一个文件系统中创建，不能跨文件系统。

### 2. 软链接 (Symbolic Link)
软链接类似于 Windows 中的快捷方式，它创建一个独立的文件，这个文件包含了指向另一个文件或目录的路径。

- **特点**:
  - **不同的 inode**: 软链接是一个独立的文件，拥有自己的 inode 和数据块，但其内容是指向另一个文件的路径。
  - **可以链接到目录**: 软链接可以指向文件或目录。
  - **跨文件系统**: 软链接可以跨文件系统指向目标文件。
  - **目标文件被删除的影响**: 如果目标文件被删除，软链接将指向一个不存在的路径，这时访问软链接会导致“无效的链接”错误。

### 使用场景
- **硬链接**: 通常用于需要为同一文件创建多个名字，同时希望所有名字都保持文件内容一致的场景。常见于备份系统或版本控制系统中。
- **软链接**: 常用于创建快捷方式或别名，特别是在需要跨文件系统或需要指向目录时。

### 示例
假设有一个文件 `file.txt`，你可以创建硬链接和软链接如下：

```bash
# 创建硬链接
ln file.txt hardlink.txt

# 创建软链接
ln -s file.txt symlink.txt
```

以上命令会创建两个新的文件 `hardlink.txt` 和 `symlink.txt`，分别作为硬链接和软链接指向原始文件 `file.txt`。

**总结**: 硬链接是多个文件名指向相同数据的方式，而软链接是独立的文件，包含了指向其他文件或目录的路径。硬链接更像是同一个文件的别名，而软链接则更像是指向目标文件的指针。


## brk()与sbrk():
* brk()和sbrk()改变程序间断点的位置。程序间断点就是程序数据段的结尾。（程序间断点是为初始化数据段的起始位置）.通过增加程序间断点进程可以更有效的申请内存 。当addr参数合理、系统有足够的内存并且不超过最大值时brk()函数将数据段结尾设置为addr,即间断点设置为addr。sbrk()将程序数据空间增加increment字节。当increment为0时则返回程序间断点的当前位置。

* 返回值：

  *  brk()成功返回0，失败返回-1并且设置errno值为ENOMEM（注：在mmap中会提到）。sbrk()成功返回之前的程序间断点地址。如果间断点值增加，那么这个指针（指的是返回的之前的间断点地址）是指向分配的新的内存的首地址。如果出错失败，就返回一个指针并设置errno全局变量的值为ENOMEM。

* 总结：

  *  这两个函数都用来改变 “program break” (程序间断点)的位置，改变数据段长度（Change data segment size），实现虚拟内存到物理内存的映射。brk()函数直接修改有效访问范围的末尾地址实现分配与回收。sbrk()参数函数中：当increment为正值时，间断点位置向后移动increment字节。同时返回移动之前的位置，相当于分配内存。当increment为负值时，位置向前移动increment字节，相当与于释放内存，其返回值没有实际意义。当increment为0时，不移动位置只返回当前位置。参数increment的符号决定了是分配还是回收内存。而关于program break的位置如图所示：
  *  ![alt text](image.png)
## 僵尸进程与孤儿进程区别
僵尸进程和孤儿进程是两种在操作系统中处理不当的进程，它们虽然都与进程的终止相关，但有着不同的概念和处理方式。

### 1. 僵尸进程 (Zombie Process)
- **定义**：僵尸进程是指一个子进程已经终止，但其父进程还没有调用 `wait()` 系列函数（如 `wait()` 或 `waitpid()`）读取子进程的退出状态信息，因此子进程的进程表项（PID 和退出状态信息）依然保存在系统中。
- **特征**：僵尸进程占用的资源非常少，仅保留其在进程表中的条目。但如果父进程不结束或不处理，进程表项将一直存在，过多的僵尸进程可能导致系统进程表资源耗尽。
- **处理方法**：父进程需要调用 `wait()` 系列函数回收子进程的资源。也可以通过终止父进程，使得操作系统将僵尸进程的父进程转移为 `init` 进程，由 `init` 进程自动清理这些僵尸进程。

### 2. 孤儿进程 (Orphan Process)
- **定义**：孤儿进程是指当一个进程的父进程先于子进程结束时，这个子进程就变成了孤儿进程。此时，孤儿进程会被 `init` 进程（在大多数 Linux 系统中是 `PID 1` 的进程）接管，成为它的子进程。
- **特征**：孤儿进程并不会造成系统资源的浪费，`init` 进程会负责监控和回收孤儿进程的资源，确保它们在终止时不会变成僵尸进程。
- **处理方法**：一般不需要特别处理，因为 `init` 进程会自动接管并清理这些孤儿进程。

### 总结
- **僵尸进程** 是已终止但未被回收的子进程，其主要问题是可能会占用系统的进程表资源。
- **孤儿进程** 是父进程终止后被 `init` 进程接管的进程，通常不会造成资源浪费。

# 如何处理僵尸进程

处理僵尸进程的主要方法是确保其父进程能够及时调用 `wait()` 系列函数来回收子进程的资源。如果父进程不能正确处理，可能需要采取其他方法。以下是几种常见的处理僵尸进程的方法：

### 1. 修改父进程代码
如果你有权访问父进程的代码，可以确保它正确地调用 `wait()` 系列函数（如 `wait()`, `waitpid()` 等），这样父进程在子进程终止时能够自动回收资源，避免僵尸进程的产生。

### 2. 使用信号处理
父进程可以通过捕获 `SIGCHLD` 信号来处理子进程的终止。`SIGCHLD` 是在子进程终止时发送给父进程的信号，通过在父进程中注册信号处理函数，当子进程终止时自动调用 `wait()` 系列函数。

```c
void sigchld_handler(int signum) {
    while (waitpid(-1, NULL, WNOHANG) > 0);
}

int main() {
    signal(SIGCHLD, sigchld_handler);
    // 其他代码
}
```

### 3. 终止父进程
如果父进程不再需要运行，且其代码无法修改，可以通过终止父进程来间接处理僵尸进程。父进程终止后，系统会将僵尸进程的父进程转移为 `init` 进程，由 `init` 进程负责回收子进程的资源。

### 4. 手动清理僵尸进程
通过终端手动查看并清理僵尸进程。首先使用 `ps -aux | grep Z` 命令查看系统中存在的僵尸进程，然后通过 `kill` 命令终止相应的父进程（如果父进程没有重要任务运行）。

```bash
ps -aux | grep Z  # 查看僵尸进程
kill -9 <parent_process_id>  # 终止父进程
```

### 5. 重启系统
在极端情况下，如果僵尸进程过多且难以处理，重启系统可以清除所有僵尸进程。但这是最后的手段，因为它会中断系统中的其他服务和进程。

### 总结
处理僵尸进程的最佳方法是在父进程中正确处理子进程的终止，使用 `wait()` 或 `SIGCHLD` 信号处理来回收资源。如果无法修改父进程代码，终止父进程或重启系统是较为直接的方式。

## mmap()与unmmap()






















# 内存管理

## linux内存布局
* ![alt text](image-1.png)

   *  代码段，包括二进制可执行代码； 
   *  数据段，包括已初始化的静态常量和全局变量； 
   *  BSS 段，包括未初始化的静态变量和全局变量； 
   *  堆段，包括动态分配的内存，从低地址开始向上增长； 
   *  文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）； 
   *  栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；
   *  
## 为什么要有虚拟内存？
1. 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
2. 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
3. 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

## malloc 是如何分配内存的？
* malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。
  * 方式一：通过 brk() 系统调用从堆分配内存 < 128kb
  * 方式二：通过 mmap() 系统调用在文件映射区域分配内存； > 128kb
* malloc() 分配的是虚拟内存。
* malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池。
* 通过 free 释放内存后，堆内存还是存在的，并没有归还给操作系统。因为与其把这 1 字节释放给操作系统，不如先缓存着放进 malloc 的内存池里，当进程再次申请 1 字节的内存时就可以直接复用，这样速度快了很多。
* 为什么不全部使用 mmap 来分配内存？
  * 频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。
* 为什么不全部使用 brk 来分配？
  * 随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。

* free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？
  * malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节，这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。

## 内存满了，会发生什么？
* 如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。
  * 后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
  * 直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。

## 哪些内存可以被回收？

* 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。
* 匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。


## 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？
* 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败
* 64位操作系统：跟 Linux 中的 overcommit_memory 参数有关：
  * 如果值为 0（默认值），代表：Heuristic overcommit handling，它允许overcommit，但过于明目张胆的overcommit会被拒绝，比如malloc一次性申请的内存大小就超过了系统总内存。Heuristic的意思是“试探式的”，内核利用某种算法猜测你的内存申请是否合理，大概可以理解为单次申请不能超过free memory + free swap + pagecache的大小 + SLAB中可回收的部分 ，超过了就会拒绝overcommit。
  * 如果值为 1，代表：Always overcommit. 允许overcommit，对内存申请来者不拒。
  * 如果值为 2，代表：Don’t overcommit. 禁止overcommit。

## 如何避免预读失效和缓存污染的问题？

* 传统的 LRU 算法法无法避免下面这两个问题：
   *  预读失效导致缓存命中率下降；
   *  缓存污染导致缓存命中率下降；
为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：
  * Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）。
  * MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。

* 但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么还存在缓存污染的问题。为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别提高了升级为热点数据的门槛：
   * Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。
   * MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
      * 如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；
      * 如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young区域；
* 通过提高了进入 active list （或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。


# 进程管理

## pcb
* PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

* 进程描述信息：
   *  进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
   *  用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；
* 进程控制和管理信息：
   *  进程当前状态，如 new、ready、running、waiting 或 blocked 等；
   *  进程优先级：进程抢占 CPU 时的优先级；
* 资源分配清单：
   *  有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。
* CPU 相关信息：
   *  CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。


## 每个 PCB 是如何组织的呢？

* 通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。

## 进程的控制

   1. 创建进程
   操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。创建进程的过程如下：
      * 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；
      * 为该进程分配运行时所必需的资源，比如内存资源；
      * 将 PCB 插入到就绪队列，等待被调度运行；

2. 终止进程
   进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。

   终止进程的过程如下：

   * 查找需要终止的进程的 PCB；
   * 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
   * 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；
   * 将该进程所拥有的全部资源都归还给操作系统；
   * 将其从 PCB 所在队列中删除；


3. 阻塞进程
   当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

   阻塞进程的过程如下：

   * 找到将要被阻塞进程标识号对应的 PCB；
   * 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
   * 将该 PCB 插入到阻塞队列中去；


4. 唤醒进程

   进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。
   如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才
   由发现者进程用唤醒语句叫醒它。

   唤醒进程的过程如下：

   * 在该事件的阻塞队列中找到相应进程的 PCB；
   * 将其从阻塞队列中移出，并置其状态为就绪状态；
   * 把该 PCB 插入到就绪队列中，等待调度程序调度；
   * 进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。